{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLfztK2c0AQ5"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "try:\n",
    "  # %tensorflow_version 仅存在于 Colab\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import math\n",
    "from keras_preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "rFmbLRzNLXI2",
    "outputId": "fc19b9a6-7924-44f2-84c8-901257c6093f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data=pd.read_csv(\"word2.csv\")\n",
    "all_img_path=train_data['PATH']\n",
    "all_label=train_data['VALUE']\n",
    "\n",
    "\n",
    "# Select the first 30000 captions from the shuffled set\n",
    "num_examples = 10000\n",
    "num_start=0\n",
    "all_img_path = all_img_path[num_start:].values\n",
    "all_label = all_label.values[num_start:]\n",
    "all_label = list('@'+l+'^' for l in all_label)\n",
    "all_img_path = list(l+\"\" for l in all_img_path)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "all_img_path,all_label=shuffle(all_img_path,all_label)\n",
    "all_img_path=all_img_path[:num_examples]\n",
    "all_label=all_label[:num_examples]\n",
    "print(len(all_label))\n",
    "print(all_label[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t7_y4Sl0ARE"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters=' ',\n",
    "      oov_token=\"<unk>\",\n",
    "      char_level=True,\n",
    "      lower=False)\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    # lang_tokenizer.word_index['<pad>'] = 0\n",
    "    # lang_tokenizer.index_word[0] = '<pad>'\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "    #max_length = max(len(t) for t in tensor)\n",
    "\n",
    "    return tensor, lang_tokenizer#, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "id": "uAy6qWtl0ARH",
    "outputId": "a33ad685-f3ac-46e0-cef1-7e2b0c9ebc9b"
   },
   "outputs": [],
   "source": [
    "sample_label,sample_lang=tokenize(all_label[1])\n",
    "print(sample_label.shape)\n",
    "print(sample_lang)\n",
    "#print(sample_length)\n",
    "\n",
    "all_label_tensor,all_label_lang=tokenize(all_label)\n",
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "convert(all_label_lang,all_label_tensor[1])\n",
    "# tf.expand_dims([all_label_lang.word_index['<unk>']] * 64, 1)\n",
    "all_label_lang.index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "0ZP10aGu0ARN",
    "outputId": "cfbc1ac0-31a0-45e1-f807-70576ed7545a"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(all_img_path)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(all_img_path)//BATCH_SIZE\n",
    "units = 256\n",
    "vocab_tar_size = len(all_label_lang.word_index)+1\n",
    "embedding_dim = 3 #embedding_dimensions =  number_of_categories**0.25\n",
    "max_length=len(all_label_tensor[0])\n",
    "features_shape = 2048\n",
    "attention_features_shape = 91\n",
    "print(max_length)\n",
    "print(vocab_tar_size)\n",
    "img_height=48\n",
    "img_width=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wv-ypaws2iZR"
   },
   "outputs": [],
   "source": [
    "img_name_train, cap_train=all_img_path,all_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1v8PRU5-QA0b"
   },
   "outputs": [],
   "source": [
    "# Create training and validation sets using an 80-20 split\n",
    "# img_name_train, img_name_val, cap_train, cap_val = train_test_split(all_img_path,\n",
    "#                                     all_label_tensor, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMYSIIgIrNI6"
   },
   "outputs": [],
   "source": [
    "def detect_contour(img):\n",
    "    size=img.shape\n",
    "    # print(size)\n",
    "    x=0\n",
    "    while not tf.reduce_any(tf.not_equal(img[:,x],1)):\n",
    "      x+=5\n",
    "    xmin=x-5 if x-5>0 else 0\n",
    "    x=size[1]-1\n",
    "    while not tf.reduce_any(tf.not_equal(img[:,x],1)):\n",
    "      x-=5\n",
    "    xmax=x+5 if x+5<size[1]-1 else size[1]-1\n",
    "\n",
    "    return 0,xmin,size[0],xmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02ulbCiVHkb0"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def slide_window(img):\n",
    "    xstep=0\n",
    "    img_patches=[]\n",
    "    while xstep < img_width-10:\n",
    "        img_patches.append(img[:,xstep:xstep+10])\n",
    "        xstep+=2\n",
    "    return img_patches\n",
    "\n",
    "def precess_image(image_path):\n",
    "\n",
    "    img = slant_correct(image_path)\n",
    "    size = img.shape\n",
    "    ymin,xmin,ymax,xmax=[0,0,size[0],size[1]]\n",
    "    # width=0\n",
    "    # img=tf.convert_to_tensor(img)\n",
    "    if (ymax-ymin)<img_height:\n",
    "        width=round((xmax-xmin)*(img_height/(ymax-ymin)))\n",
    "    else:\n",
    "        width=round((xmax-xmin)/((ymax-ymin)/img_height))\n",
    "    if width>img_width:\n",
    "        img = cv2.resize(img.numpy(),(img_width,img_height))\n",
    "        width=img_width\n",
    "    else:\n",
    "        img = cv2.resize(img.numpy(),(width,img_height))\n",
    "    \n",
    "    img=tf.pad(img,[[0,0],[0,img_width-width]],constant_values=1)\n",
    "    img_patches=slide_window(img)\n",
    "    return img_patches\n",
    "\n",
    "def show_patches(img):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    i=0\n",
    "    #sample_image=tf.reshape(sample_image,(y,x))\n",
    "    for i in range(len(img)):\n",
    "        ax = fig.add_subplot(10, 10, i+1)\n",
    "        ax.set_title(str(i))\n",
    "        ax.imshow(img[i],cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def slant_correct(file_path):\n",
    "    img = cv2.imread(file_path)#,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, binary = cv2.threshold(gray,230,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    binary = 255 - binary\n",
    "    contours, hierarchy = cv2.findContours(binary,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    sum_theta = 0\n",
    "    sum_weight = 0\n",
    "    for line in range(len(contours)):\n",
    "\n",
    "        cv2.drawContours(img,contours[line],-1,(0,0,255),3) \n",
    "\n",
    "        columns = []\n",
    "\n",
    "        for i in range(1,len(contours[line])):\n",
    "            columns.append(contours[line][i]-contours[line][i - 1])\n",
    "        columns.append(contours[line][0]-contours[line][-1])\n",
    "\n",
    "        a = []\n",
    "\n",
    "        for i in range(len(columns)):\n",
    "            if columns[i][0][0] == 0 and columns[i][0][1] == -1:\n",
    "                a.append(6)\n",
    "            elif columns[i][0][0] == 0 and columns[i][0][1] == 1:\n",
    "                a.append(2)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == 1:\n",
    "                a.append(1)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == 0:\n",
    "                a.append(0)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == -1:\n",
    "                a.append(7)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == 1:\n",
    "                a.append(3)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == 0:\n",
    "                a.append(4)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == -1:\n",
    "                a.append(5)\n",
    "\n",
    "        THRESH_V=1\n",
    "        status=np.zeros_like(a)\n",
    "\n",
    "        v_up = [2, 1, 0, 1, 2, 3, 4, 3]\n",
    "        v_down = [2, 3, 4, 3, 2, 1, 0, 1]\n",
    "        for i in range(len(a)):\n",
    "            sum_slope_up = 0\n",
    "            sum_slope_down = 0\n",
    "            array=[]\n",
    "            array.append(i-2)\n",
    "            array.append(i-1)\n",
    "            array.append(i)\n",
    "            array.append(i+1 if i+1<len(a) else i+1-len(a))\n",
    "            array.append(i+2 if i+2<len(a) else i+2-len(a))\n",
    "            for j in array:\n",
    "                sum_slope_up = sum_slope_up + v_up[a[j]]\n",
    "                sum_slope_down = sum_slope_down + v_down[a[j]]\n",
    "\n",
    "            if sum_slope_up < THRESH_V:\n",
    "                status[i] = 1\n",
    "            if sum_slope_down < THRESH_V:\n",
    "                status[i] = -1\n",
    "        cv2.waitKey(0)\n",
    "#         print(status)\n",
    "        p=contours[line][np.where(status==0)]\n",
    "\n",
    "        try:\n",
    "            for k in range(len(p)-1):\n",
    "\n",
    "                dirt=p[k][0]-p[k+1][0]\n",
    "                theta=-1*(dirt[1]/dirt[0])\n",
    "                if theta>=0:\n",
    "                    theta=theta if theta<1 else 1.\n",
    "                else:\n",
    "                    theta=theta if theta>-1 else -1.\n",
    "                \n",
    "                sum_theta+=theta*abs(dirt[1])\n",
    "                sum_weight+=abs(dirt[1])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    h,w = gray.shape\n",
    "    res = gray\n",
    "    if sum_weight!=0:\n",
    "      M=np.array([[1,sum_theta/sum_weight,0.5*w*abs(sum_theta/sum_weight)],[0,1,0]])\n",
    "      res = cv2.warpAffine(gray, M,(w*2, h),flags=cv2.INTER_CUBIC,borderValue=(255))\n",
    "      res=tf.cast(res,dtype=tf.float32)/255.\n",
    "      res=tf.where(res>0.88,tf.ones_like(res),res)\n",
    "      try:\n",
    "        ymin,xmin,ymax,xmax = detect_contour(res)\n",
    "        return res[ymin:ymax,xmin:xmax]\n",
    "      except:\n",
    "        return res\n",
    "    else:\n",
    "      res=tf.cast(res,dtype=tf.float32)/255.\n",
    "      res=tf.where(res>0.88,tf.ones_like(res),res)\n",
    "      return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "colab_type": "code",
    "id": "TclW14oqzTXS",
    "outputId": "88c3bc72-c3d4-41d6-a011-d36c18866ed5"
   },
   "outputs": [],
   "source": [
    "i=np.random.randint(0,len(all_img_path),1)[0]\n",
    "# img=precess_image(\"words/m04/m04-043/m04-043-00-08.png\")\n",
    "img=precess_image(all_img_path[i])\n",
    "# words/b06/b06-082/b06-082-09-02.png\n",
    "# words/m04/m04-043/m04-043-00-08.png\n",
    "# words/g06/g06-031c/g06-031c-01-04.png\n",
    "# plt.imshow(img[5],cmap='gray')\n",
    "show_patches(img)\n",
    "print(all_label[i])\n",
    "img=tf.convert_to_tensor(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1N9C30dGFb8g"
   },
   "outputs": [],
   "source": [
    "# Load the numpy files\n",
    "def map_func(img_name, cap):\n",
    "    name = img_name.decode('utf-8')\n",
    "    img_tensor = tf.convert_to_tensor(precess_image(name))\n",
    "    return img_tensor, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWrXJQif0ARv"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((all_img_path, all_label_tensor))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# Use map to load the numpy files in parallel\n",
    "dataset = dataset.map(lambda item1, item2: tf.numpy_function(# 包上np函数作为tf函数\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCviV8uf0ARy"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, enc_units,batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.conv1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(20,5,strides=1,\n",
    "                                          activation='relu',\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer='he_uniform'))\n",
    "        self.maxpool1 = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D((2,2)))\n",
    "        self.conv2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(50,5,strides=1,\n",
    "                                            activation='relu',\n",
    "                                            padding='same',\n",
    "                                            kernel_initializer='he_uniform'))\n",
    "        self.maxpool2 = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D((2,2)))\n",
    "        self.flatten = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
    "        self.dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024))\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        \n",
    "        self.LSTM = tf.keras.layers.LSTM(self.enc_units,  \n",
    "                                         return_sequences=True)\n",
    "        self.BLSTM = tf.keras.layers.Bidirectional(self.LSTM)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.LSTM2 = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.BLSTM2=tf.keras.layers.Bidirectional(self.LSTM2)\n",
    "\n",
    "    def call(self, img, hidden):\n",
    "        x=tf.expand_dims(img,-1)\n",
    "        # print(batch_seq.shape)\n",
    "        print(x.shape)\n",
    "        x=self.conv1(x)\n",
    "        x=self.maxpool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.maxpool2(x) \n",
    "        x=self.flatten(x)\n",
    "        x=self.dense(x)\n",
    "        x=self.dropout1(x)\n",
    "        output = self.BLSTM(x)#h短期记忆,c长期记忆\n",
    "        output = self.dropout2(output)\n",
    "        # output = self.BLSTM3(output)\n",
    "        output, state_h, state_c, b_state_h, b_state_c = self.BLSTM2(output)\n",
    "        # output, state_h, state_c = self.BLSTM2(output)\n",
    "        return output, [tf.concat([state_h,b_state_h],axis=-1),tf.concat([state_c,b_state_c],axis=-1)]\n",
    "        # return output, [state_h,state_c]\n",
    "\n",
    "\n",
    "    def initialize_hidden_state(self,batch_sz):\n",
    "        return tf.zeros((batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "XV3lzwh7zTXj",
    "outputId": "9ad787ed-7476-445d-8196-987eb484f047"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(units,BATCH_SIZE)\n",
    "# image_dataset=tf.data.Dataset.from_generator(load_image,(tf.float32,tf.string)).batch(BATCH_SIZE)\n",
    "hidden=encoder.initialize_hidden_state(BATCH_SIZE)\n",
    "\n",
    "sample_output,sample_hidden=encoder(tf.expand_dims(precess_image(all_img_path[1]), 0),hidden)\n",
    "print(\"sample_output shape: (batch size, sequence_length, units) {}\".format(sample_output.shape))\n",
    "print(\"sample_hidden shape: (1, units) {}\".format(sample_hidden[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XjC2u_O0AR5"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # 隐藏层的形状 == （批大小，隐藏层大小）\n",
    "        # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
    "        # 这样做是为了执行加法以计算分数  \n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # 分数的形状 == （批大小，最大长度，1）\n",
    "        # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
    "        # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
    "        score = self.V(tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "oGXwbS6N0AR9",
    "outputId": "587c3384-3c5e-4bfd-ae18-c73388f1ca1a"
   },
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(units)\n",
    "attention_result, attention_weights = attention_layer(sample_output,sample_hidden[1])\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDE1Vl2E0ASA"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units, \n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "                                      \n",
    "        self.fc1 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # 用于注意力\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, enc_output, hidden):\n",
    "        # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
    "        context_vector, attention_weights = self.attention(enc_output, hidden[1])\n",
    "        # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 将合并后的向量传送到 GRU\n",
    "        output, state_h, state_c = self.lstm(x,hidden)\n",
    "\n",
    "        output = tf.concat([tf.expand_dims(context_vector, 1), output], axis=-1)\n",
    "\n",
    "        output = self.fc1(output)\n",
    "        # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        return output, [state_h,state_c], attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KNmp4HEj0ASE",
    "outputId": "bb9323c8-797d-4849-84a5-2bc371cecc44"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units*2)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((1, 1)), sample_output, sample_hidden)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8A4rpXIk0ASL"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,decay=0.02)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "acc_object=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  # loss_ = loss_object(real,tf.clip_by_value(pred,1e-15,1.0))\n",
    "  loss_ = loss_object(real,pred)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "\n",
    "def acc_function(real,pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  acc_ = acc_object(real, pred)\n",
    "  mask = tf.cast(mask, dtype=acc_.dtype)\n",
    "  acc_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(acc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqKXbhea0ASQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_path = './training_checkpoints/81_train'\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDS_Mhlj3Any"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "  # restoring the latest checkpoint in checkpoint_path\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8qe075t0ASS"
   },
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell\n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXoFNzf_0ASW"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    acc=0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        # tf.print(enc_hidden)\n",
    "        dec_input = tf.expand_dims([all_label_lang.word_index['@']]*inp.shape[0], 1)\n",
    "        # print(dec_input)\n",
    "        # 教师强制 - 将目标词作为下一个输入\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # 将编码器输出 （enc_output） 传送至解码器\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, enc_output, dec_hidden)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            acc += acc_function(targ[:,t],predictions)\n",
    "            # 使用教师强制\n",
    "            # print(targ[:,t])\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    acc=acc/int(targ.shape[1])\n",
    "    #print(batch_loss.numpy())\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss,batch_loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhj0ZSfwzTYK"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def vad_step(inp, targ,enc_hidden):\n",
    "\n",
    "    enc_output, enc_hidden = encoder(inp,enc_hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([all_label_lang.word_index['@']]*inp.shape[0], 1)\n",
    "\n",
    "    acc=0\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, enc_output, dec_hidden)\n",
    "      \n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "      acc += acc_function(targ[:,t],predictions)\n",
    "      dec_input = tf.expand_dims(predicted_id, 1)\n",
    "\n",
    "    return acc/ int(targ.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PP1CacJp_vsy"
   },
   "outputs": [],
   "source": [
    "start_epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_ZDPfAv00ASZ",
    "outputId": "30188947-0159-434e-fae1-6244e701cf13",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "import time\n",
    "for epoch in range(start_epoch,EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    \n",
    "    for (batch,(inp,targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        enc_hidden=encoder.initialize_hidden_state(BATCH_SIZE)\n",
    "        # print(targ)\n",
    "        t_loss,batch_loss,acc = train_step(inp, targ,enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        total_acc+=acc\n",
    "        if batch % 2 == 0:\n",
    "            # print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "            print('Epoch {} Batch {} Loss {:.4f} acc {:.4f}'.format(epoch + 1, batch, batch_loss.numpy(),acc.numpy()))\n",
    "            \n",
    "    loss_plot.append(total_loss / steps_per_epoch)\n",
    "    \n",
    "    # total_acc = vad_step()\n",
    "    # validsize=round(steps_per_epoch*0.2)\n",
    "    # for (vbatch,(vinp,vtarg)) in enumerate(dataset.skip(np.random.randint(0,steps_per_epoch-validsize,size=1)[0]).take(validsize)):\n",
    "    #   batch_acc = vad_step(vinp, vtarg,enc_hidden)\n",
    "    #   total_acc += batch_acc\n",
    "\n",
    "      \n",
    "    # 每 2 个周期（epoch），保存（检查点）一次模型\n",
    "    # if (epoch + 1) % 2 == 0:\n",
    "    # ckpt_manager.save()\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f} Acc {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch, total_acc / steps_per_epoch))\n",
    "    # print('Epoch {} Loss {:.4f} '.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MHZJ5aka0ASe"
   },
   "outputs": [],
   "source": [
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "\n",
    "    hidden = encoder.initialize_hidden_state(1)\n",
    "    temp_input = tf.expand_dims(tf.convert_to_tensor(precess_image(image)), 0)\n",
    "    # print(temp_input.shape)\n",
    "    features,hidden = encoder(temp_input,hidden)\n",
    "\n",
    "    dec_input = tf.expand_dims([all_label_lang.word_index['@']], 0)\n",
    "    # print(dec_input)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
    "\n",
    "        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, 1).numpy()[0]\n",
    "        # predicted_id=tf.random.categorical(predictions,1)[0][0].numpy()\n",
    "        print(predicted_id)\n",
    "        result.append(all_label_lang.index_word[predicted_id])\n",
    "\n",
    "        if all_label_lang.index_word[predicted_id] == '^':\n",
    "            return result, attention_plot\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    attention_plot = attention_plot[:len(result), :]\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUieiUUZ0ASi"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "def plot_attention(image, result, attention_plot):\n",
    "    img = cv2.imread(image,cv2.IMREAD_GRAYSCALE)\n",
    "    size = img.shape\n",
    "    ymin,xmin,ymax,xmax=[0,0,size[0],size[1]]\n",
    "    if (ymax-ymin)<img_height:\n",
    "        width=round((xmax-xmin)*(img_height/(ymax-ymin)))\n",
    "    else:\n",
    "        width=round((xmax-xmin)/((ymax-ymin)/img_height))\n",
    "    if width>img_width:\n",
    "        img = cv2.resize(img,(img_width,img_height),cv2.INTER_AREA)\n",
    "        width=img_width\n",
    "    else:\n",
    "        img = cv2.resize(img,(width,img_height),cv2.INTER_AREA)\n",
    "    img = tf.cast(img,tf.float32)/255.\n",
    "    img=tf.where(img>0.88,tf.ones_like(img),img)\n",
    "    timg=tf.pad(img,[[0,0],[0,img_width-width]],constant_values=1)\n",
    "    fig = plt.figure(figsize=(100, 100))\n",
    "\n",
    "    len_result = len(result)\n",
    "    print(len_result)\n",
    "    for l in range(len_result):\n",
    "        temp_att = attention_plot[l]\n",
    "        ax = fig.add_subplot(len_result+1//2, len_result+1//2, l+1)\n",
    "        ax.set_title(result[l])\n",
    "        \n",
    "        img = ax.imshow(timg,cmap='gray')\n",
    "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "PcKTOQlJ0ASm",
    "outputId": "227f5962-4aad-440f-c442-4309d549abe7"
   },
   "outputs": [],
   "source": [
    "# captions on the validation set\n",
    "rid = np.random.randint(0, len(all_img_path))\n",
    "image = all_img_path[rid]\n",
    "print(image)\n",
    "real_caption=all_label[rid]\n",
    "result, attention_plot = evaluate(image)\n",
    "\n",
    "print ('Real Caption:', real_caption)\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "plot_attention(image, result, attention_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "87R_yh7HeMPD",
    "outputId": "2574736a-23ae-468f-f96b-76ca56041a7d"
   },
   "outputs": [],
   "source": [
    "p=\"words/b01/b01-023/b01-023-00-04.png\"\n",
    "' '.join(evaluate(p)[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“word_4_19.ipynb”的副本attention版本实验",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
