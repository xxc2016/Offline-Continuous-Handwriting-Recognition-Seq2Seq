{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"word_4_19.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1w-mu4xtSUIiUCcxbROUfA-sfj2-1ADTL\n",
    "\"\"\"\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import difflib \n",
    "import pandas as pd\n",
    "\n",
    "units = 256\n",
    "vocab_tar_size = 81\n",
    "embedding_dim = 3 #embedding_dimensions =  number_of_categories**0.25\n",
    "max_length=18\n",
    "attention_features_shape = 91\n",
    "img_height=48\n",
    "img_width=192\n",
    "\n",
    "def detect_contour(img):\n",
    "    size=img.shape\n",
    "    # print(size)\n",
    "    x=0\n",
    "    while not tf.reduce_any(tf.not_equal(img[:,x],1)):\n",
    "        x+=5\n",
    "    xmin=x-5 if x-5>0 else 0\n",
    "    x=size[1]-1\n",
    "    while not tf.reduce_any(tf.not_equal(img[:,x],1)):\n",
    "        x-=5\n",
    "    xmax=x+5 if x+5<size[1]-1 else size[1]-1\n",
    "    \n",
    "    y=0\n",
    "    while not tf.reduce_any(tf.not_equal(img[y,:],1)):\n",
    "        y+=7\n",
    "    ymin=y-7 if y-7>0 else 0\n",
    "    y=size[0]-1\n",
    "    while not tf.reduce_any(tf.not_equal(img[y,:],1)):\n",
    "        y-=7\n",
    "    ymax=y+7 if y+7<size[0]-1 else size[0]-1\n",
    "    \n",
    "    return ymin,xmin,ymax,xmax\n",
    "\n",
    "def slide_window(img):\n",
    "    xstep=0\n",
    "    img_patches=[]\n",
    "    while xstep < img_width-10:\n",
    "        img_patches.append(img[:,xstep:xstep+10])\n",
    "        xstep+=2\n",
    "    return img_patches\n",
    "\n",
    "def precess_image(image):\n",
    "\n",
    "    img = slant_correct(image)\n",
    "    size = img.shape\n",
    "    ymin,xmin,ymax,xmax=[0,0,size[0],size[1]]\n",
    "    # width=0\n",
    "    # img=tf.convert_to_tensor(img)\n",
    "    if (ymax-ymin)<img_height:\n",
    "        width=round((xmax-xmin)*(img_height/(ymax-ymin)))\n",
    "    else:\n",
    "        width=round((xmax-xmin)/((ymax-ymin)/img_height))\n",
    "    if width>img_width:\n",
    "        img = cv2.resize(img.numpy(),(img_width,img_height))\n",
    "        width=img_width\n",
    "    else:\n",
    "        img = cv2.resize(img.numpy(),(width,img_height))\n",
    "    \n",
    "    # img = tf.cast(img,tf.float32)/255.\n",
    "    # img=tf.where(img>0.88,tf.ones_like(img),img)\n",
    "    # # img=1.-img\n",
    "    img=tf.pad(img,[[0,0],[0,img_width-width]],constant_values=1)\n",
    "    # plt.imshow(img,cmap='gray')\n",
    "    # print(img.numpy())\n",
    "    img_patches=slide_window(img)\n",
    "    # print(img_patches[90].numpy())\n",
    "    return img_patches\n",
    "\n",
    "def show_patches(img):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    i=0\n",
    "    #sample_image=tf.reshape(sample_image,(y,x))\n",
    "    for i in range(len(img)):\n",
    "        ax = fig.add_subplot(10, 10, i+1)\n",
    "        ax.set_title(str(i))\n",
    "        ax.imshow(img[i],cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def slant_correct(gray):\n",
    "#     img = cv2.imread(file_path)#,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, binary = cv2.threshold(gray,230,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    binary = 255 - binary\n",
    "    contours, hierarchy = cv2.findContours(binary,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    sum_theta = 0\n",
    "    sum_weight = 0\n",
    "    for line in range(len(contours)):\n",
    "\n",
    "#         cv2.drawContours(img,contours[line],-1,(0,0,255),3) \n",
    "\n",
    "        columns = []\n",
    "\n",
    "        for i in range(1,len(contours[line])):\n",
    "            columns.append(contours[line][i]-contours[line][i - 1])\n",
    "        columns.append(contours[line][0]-contours[line][-1])\n",
    "\n",
    "        a = []\n",
    "\n",
    "        for i in range(len(columns)):\n",
    "            if columns[i][0][0] == 0 and columns[i][0][1] == -1:\n",
    "                a.append(6)\n",
    "            elif columns[i][0][0] == 0 and columns[i][0][1] == 1:\n",
    "                a.append(2)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == 1:\n",
    "                a.append(1)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == 0:\n",
    "                a.append(0)\n",
    "            elif columns[i][0][0] == 1 and columns[i][0][1] == -1:\n",
    "                a.append(7)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == 1:\n",
    "                a.append(3)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == 0:\n",
    "                a.append(4)\n",
    "            elif columns[i][0][0] == -1 and columns[i][0][1] == -1:\n",
    "                a.append(5)\n",
    "\n",
    "        THRESH_V=1\n",
    "        status=np.zeros_like(a)\n",
    "\n",
    "        v_up = [2, 1, 0, 1, 2, 3, 4, 3]\n",
    "        v_down = [2, 3, 4, 3, 2, 1, 0, 1]\n",
    "        for i in range(len(a)):\n",
    "            sum_slope_up = 0\n",
    "            sum_slope_down = 0\n",
    "            array=[]\n",
    "            array.append(i-2)\n",
    "            array.append(i-1)\n",
    "            array.append(i)\n",
    "            array.append(i+1 if i+1<len(a) else i+1-len(a))\n",
    "            array.append(i+2 if i+2<len(a) else i+2-len(a))\n",
    "            for j in array:\n",
    "                sum_slope_up = sum_slope_up + v_up[a[j]]\n",
    "                sum_slope_down = sum_slope_down + v_down[a[j]]\n",
    "#             print(sum_slope_up,sum_slope_down)\n",
    "#             if(sum_slope_up==sum_slope_down):status[i]=2\n",
    "            if sum_slope_up < THRESH_V:\n",
    "                status[i] = 1\n",
    "            if sum_slope_down < THRESH_V:\n",
    "                status[i] = -1\n",
    "        cv2.waitKey(0)\n",
    "#         print(status)\n",
    "        p=contours[line][np.where(status==0)]\n",
    "\n",
    "        try:\n",
    "            for k in range(len(p)-1):\n",
    "\n",
    "                dirt=p[k][0]-p[k+1][0]\n",
    "                theta=-1*(dirt[1]/dirt[0])\n",
    "                if theta>=0:\n",
    "                    theta=theta if theta<1 else 1.\n",
    "                else:\n",
    "                    theta=theta if theta>-1 else -1.\n",
    "                \n",
    "                sum_theta+=theta*abs(dirt[1])\n",
    "                sum_weight+=abs(dirt[1])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    h,w = gray.shape\n",
    "    res = gray\n",
    "    if sum_weight!=0:\n",
    "        M=np.array([[1,sum_theta/sum_weight,0.5*w*abs(sum_theta/sum_weight)],[0,1,0]])\n",
    "        res = cv2.warpAffine(gray, M,(w*2, h),flags=cv2.INTER_CUBIC,borderValue=(255))\n",
    "        res=tf.cast(res,dtype=tf.float32)/255.\n",
    "        res=tf.where(res>0.88,tf.ones_like(res),res)\n",
    "        try:\n",
    "            ymin,xmin,ymax,xmax = detect_contour(res)\n",
    "            return res[ymin:ymax,xmin:xmax]\n",
    "        except:\n",
    "            return res\n",
    "    else:\n",
    "        res=tf.cast(res,dtype=tf.float32)/255.\n",
    "        res=tf.where(res>0.88,tf.ones_like(res),res)\n",
    "        return res\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.conv1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(20,5,strides=1,\n",
    "                                          activation='relu',\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer='he_uniform'))\n",
    "        self.maxpool1 = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D((2,2)))\n",
    "        self.conv2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(50,5,strides=1,\n",
    "                                            activation='relu',\n",
    "                                            padding='same',\n",
    "                                            kernel_initializer='he_uniform'))\n",
    "        self.maxpool2 = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D((2,2)))\n",
    "        self.flatten = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
    "        self.dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024))\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        \n",
    "        self.LSTM = tf.keras.layers.LSTM(self.enc_units,  \n",
    "                                         return_sequences=True)\n",
    "        self.BLSTM = tf.keras.layers.Bidirectional(self.LSTM)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.LSTM2 = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.BLSTM2=tf.keras.layers.Bidirectional(self.LSTM2)\n",
    "        # self.LSTM3 = tf.kears,layers.LSTM(self.enc_units,\n",
    "        #                                   return_sequences=True)\n",
    "        # self.BLSTM3=tf.kears.layers.Bidirectional(self.LSTM3)\n",
    "\n",
    "    def call(self, img, hidden):\n",
    "        x=tf.expand_dims(img,-1)\n",
    "        # print(batch_seq.shape)\n",
    "        # print(x.shape)\n",
    "        x=self.conv1(x)\n",
    "        x=self.maxpool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.maxpool2(x) \n",
    "        x=self.flatten(x)\n",
    "        x=self.dense(x)\n",
    "        x=self.dropout1(x)\n",
    "        output = self.BLSTM(x)#h短期记忆,c长期记忆\n",
    "        output = self.dropout2(output)\n",
    "        # output = self.BLSTM3(output)\n",
    "        output, state_h, state_c, b_state_h, b_state_c = self.BLSTM2(output)\n",
    "        # output, state_h, state_c = self.BLSTM2(output)\n",
    "        return output, [tf.concat([state_h,b_state_h],axis=-1),tf.concat([state_c,b_state_c],axis=-1)]\n",
    "        # return output, [state_h,state_c]\n",
    "\n",
    "\n",
    "    def initialize_hidden_state(self,batch_sz):\n",
    "        return tf.zeros((batch_sz, self.enc_units))\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # 隐藏层的形状 == （批大小，隐藏层大小）\n",
    "        # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
    "        # 这样做是为了执行加法以计算分数  \n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # 分数的形状 == （批大小，最大长度，1）\n",
    "        # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
    "        # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
    "        score = self.V(tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units, \n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "                                      \n",
    "        self.fc1 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # 用于注意力\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, enc_output, hidden):\n",
    "        # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
    "        context_vector, attention_weights = self.attention(enc_output, hidden[1])\n",
    "        # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # x = tf.expand_dims(x,1)\n",
    "        # 将合并后的向量传送到 GRU\n",
    "        output, state_h, state_c = self.lstm(x,hidden)\n",
    "\n",
    "        output = tf.concat([tf.expand_dims(context_vector, 1), output], axis=-1)\n",
    "\n",
    "        output = self.fc1(output)\n",
    "        # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        return output, [state_h,state_c], attention_weights\n",
    "\n",
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "\n",
    "    hidden = encoder.initialize_hidden_state(1)\n",
    "    temp_input = tf.expand_dims(tf.convert_to_tensor(precess_image(image)), 0)\n",
    "    # print(temp_input.shape)\n",
    "    features,hidden = encoder(temp_input,hidden)\n",
    "\n",
    "    dec_input = tf.expand_dims([all_label_lang.word_index['@']], 0)\n",
    "    # print(dec_input)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
    "\n",
    "        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, 1).numpy()[0]\n",
    "        # predicted_id=tf.random.categorical(predictions,1)[0][0].numpy()\n",
    "        # print(predicted_id)\n",
    "        result.append(all_label_lang.index_word[predicted_id])\n",
    "        \n",
    "        if all_label_lang.index_word[predicted_id] == '^':\n",
    "            return result, attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    attention_plot = attention_plot[:len(result), :]\n",
    "    return result, attention_plot\n",
    "\n",
    "def cut_word(img):\n",
    "    ymin,xmin,ymax,xmax = detect_contour(img)\n",
    "    oimg = img[ymin:ymax,xmin:xmax]\n",
    "\n",
    "    kernel = np.ones((5,17),np.uint8)\n",
    "    img = cv2.erode(oimg,kernel)\n",
    "    img=cv2.GaussianBlur(img,(15,15),100)\n",
    "    img = tf.cast(img,tf.float32)/255.\n",
    "    img = 1 - img\n",
    "    y = tf.reduce_sum(img,axis=0)\n",
    "    x = np.arange(0,int(y.shape[0]),1)\n",
    "\n",
    "    indexs=tf.where(tf.equal(y,tf.reduce_min(y)))\n",
    "    pre=0\n",
    "    res=[]\n",
    "\n",
    "    for i in range(1,indexs.shape[0]):\n",
    "        if indexs[i]-indexs[i-1]>1:\n",
    "            res.extend((indexs[pre].numpy()+indexs[i-1].numpy())//2)\n",
    "            pre=i\n",
    "    res.extend((indexs[-1].numpy()+indexs[pre].numpy())//2)\n",
    "    res.append(img.shape[1])\n",
    "    pre=0\n",
    "    result=[]\n",
    "    for i in range(len(res)):\n",
    "        result.append(oimg[:,pre:res[i]])\n",
    "        pre=res[i]\n",
    "    return result\n",
    "\n",
    "def minDistance(word1, word2):\n",
    "        n1 = len(word1)\n",
    "        n2 = len(word2)\n",
    "        dp = [[0] * (n2 + 1) for _ in range(n1 + 1)]\n",
    "        # 第一行\n",
    "        for j in range(1, n2 + 1):\n",
    "            dp[0][j] = dp[0][j-1] + 1\n",
    "        # 第一列\n",
    "        for i in range(1, n1 + 1):\n",
    "            dp[i][0] = dp[i-1][0] + 1\n",
    "        for i in range(1, n1 + 1):\n",
    "            for j in range(1, n2 + 1):\n",
    "                if word1[i-1] == word2[j-1]:\n",
    "                    dp[i][j] = dp[i-1][j-1]\n",
    "                else:\n",
    "                    dp[i][j] = min(dp[i][j-1], dp[i-1][j], dp[i-1][j-1] ) + 1\n",
    "        #print(dp)      \n",
    "        return dp[-1][-1]\n",
    "\n",
    "def lexicon(a):\n",
    "    da=pd.read_csv(\"C:/Users/sss/Desktop/spell.csv\")\n",
    "    p=da['WORD'].values\n",
    "    max_ratio=10\n",
    "    max_index=0\n",
    "\n",
    "    for t in range(len(p)):\n",
    "        tmp=minDistance(a,p[t])\n",
    "        if tmp<=max_ratio:\n",
    "            max_index=t\n",
    "            max_ratio=tmp\n",
    "\n",
    "        if max_ratio==0:\n",
    "            return p[max_index]\n",
    "        \n",
    "    return p[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: divide by zero encountered in int_scalars\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3333: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore,QtGui,QtWidgets\n",
    "from PyQt5.QtWidgets import *\n",
    "import sys\n",
    "import qtawesome\n",
    "import os\n",
    " \n",
    "class MainUi(QtWidgets.QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "        self.init_style()\n",
    "        self.setWindowTitle(\"识别程序\")\n",
    "        self.cwd = os.getcwd() # 获取当前程序文件位置\n",
    "        self.model = 0\n",
    "#         self.setWindowOpacity(0.9) # 设置窗口透明度\n",
    "#         self.setAttribute(QtCore.Qt.WA_TranslucentBackground) # 设置窗口背景透明\n",
    "        self.setWindowFlag(QtCore.Qt.FramelessWindowHint) # 隐藏边框\n",
    "        self.main_layout.setSpacing(0)\n",
    "        self.img_path=''\n",
    "        \n",
    "\n",
    "    def init_ui(self):\n",
    "        self.setFixedSize(960,700)\n",
    "        self.main_widget = QtWidgets.QWidget()  # 创建窗口主部件\n",
    "        self.main_layout = QtWidgets.QGridLayout()  # 创建主部件的网格布局\n",
    "        self.main_widget.setLayout(self.main_layout)  # 设置窗口主部件布局为网格布局\n",
    " \n",
    "        self.left_widget = QtWidgets.QWidget()  # 创建左侧部件\n",
    "        self.left_widget.setObjectName('left_widget')\n",
    "        self.left_layout = QtWidgets.QGridLayout()  # 创建左侧部件的网格布局层\n",
    "        self.left_widget.setLayout(self.left_layout) # 设置左侧部件布局为网格\n",
    " \n",
    "        self.right_widget = QtWidgets.QWidget() # 创建右侧部件\n",
    "        self.right_widget.setObjectName('right_widget')\n",
    "        self.right_layout = QtWidgets.QGridLayout()\n",
    "        self.right_widget.setLayout(self.right_layout) # 设置右侧部件布局为网格\n",
    " \n",
    "        self.main_layout.addWidget(self.left_widget,0,0,12,2) # 左侧部件在第0行第0列，占8行3列\n",
    "        self.main_layout.addWidget(self.right_widget,0,2,12,10) # 右侧部件在第0行第3列，占8行9列\n",
    "        self.setCentralWidget(self.main_widget) # 设置窗口主部件\n",
    "        \n",
    "        self.left_ocr = QtWidgets.QPushButton(\"识别\") # 关闭按钮\n",
    "        self.left_close = QtWidgets.QPushButton(\"\") # 空白按钮\n",
    "        self.left_mini = QtWidgets.QPushButton(\"\")  # 最小化按钮\n",
    "\n",
    "        self.left_button_1 = QtWidgets.QPushButton(qtawesome.icon('fa.music',color='white'),\"文本行识别\")\n",
    "        self.left_button_1.setObjectName('left_button')\n",
    "        self.left_button_2 = QtWidgets.QPushButton(qtawesome.icon('fa.sellsy',color='white'),\"单词识别\")\n",
    "        self.left_button_2.setObjectName('left_button')\n",
    "        \n",
    "        self.left_button_1.clicked.connect(self.line_ocr)\n",
    "        self.left_button_2.clicked.connect(self.word_ocr)\n",
    "        self.left_ocr.clicked.connect(self.do_ocr)\n",
    "        self.left_layout.addWidget(self.left_mini, 0, 0,1,1)\n",
    "        self.left_layout.addWidget(self.left_ocr, 0, 2,1,1)\n",
    "        self.left_layout.addWidget(self.left_close, 0, 1, 1, 1)\n",
    "        self.left_layout.addWidget(self.left_button_1, 1, 0,1,3)\n",
    "        self.left_layout.addWidget(self.left_button_2, 2, 0,1,3)\n",
    "        \n",
    "        self.right_bar_widget = QtWidgets.QWidget() # 右侧顶部搜索框部件\n",
    "        self.right_bar_layout = QtWidgets.QGridLayout() # 右侧顶部搜索框网格布局\n",
    "        self.right_bar_widget.setLayout(self.right_bar_layout)\n",
    "        \n",
    "        self.search_icon = QtWidgets.QPushButton(chr(0xf002) + ' '+'选择图片')\n",
    "        self.search_icon.setFont(qtawesome.font('fa', 16))\n",
    "        self.right_bar_widget_search_input = QtWidgets.QLineEdit()\n",
    "#         self.right_bar_widget_search_input.setReadOnly(True)\n",
    "        self.right_bar_widget_search_input.setPlaceholderText(\"图片路径\")\n",
    "\n",
    "        self.search_icon.clicked.connect(self.slot_btn_chooseFile)\n",
    "        self.right_bar_layout.addWidget(self.search_icon,0,0,1,1)\n",
    "        self.right_bar_layout.addWidget(self.right_bar_widget_search_input,0,1,1,8)\n",
    "\n",
    "        self.right_layout.addWidget(self.right_bar_widget, 0, 0, 1, 9)\n",
    "        \n",
    "        self.right_picture_label = QtWidgets.QLabel(\"选取图片\")\n",
    "        self.right_picture_label.setObjectName('right_picture')\n",
    "        self.right_picture = QtWidgets.QLabel(\"\")\n",
    "#         self.right_picture.setFixedSize(300, 200)\n",
    "        self.right_result_label = QtWidgets.QLabel(\"识别结果\")\n",
    "        self.right_result_label.setObjectName('right_label')\n",
    "        self.right_result = QtWidgets.QLabel(\"\")\n",
    "\n",
    "        \n",
    "        self.right_layout.addWidget(self.right_picture_label, 1, 0, 1, 9)\n",
    "        self.right_layout.addWidget(self.right_result_label, 3, 0, 1, 9)\n",
    "        self.right_layout.addWidget(self.right_picture, 2, 0, 1, 9)\n",
    "        self.right_layout.addWidget(self.right_result, 4, 0, 1, 9)\n",
    "        \n",
    "    def init_style(self):\n",
    "        self.left_ocr.setStyleSheet('''QPushButton{background:#F76677;border-radius:5px;}QPushButton:hover{background:red;}''')\n",
    "        self.left_close.setStyleSheet('''QPushButton{background:#F7D674;border-radius:5px;}QPushButton:hover{background:yellow;}''')\n",
    "        self.left_mini.setStyleSheet('''QPushButton{background:#6DDF6D;border-radius:5px;}QPushButton:hover{background:green;}''')\n",
    "        \n",
    "        self.left_widget.setStyleSheet('''\n",
    "            QPushButton{border:none;color:white;}\n",
    "            QPushButton#left_label{\n",
    "                border:none;\n",
    "                border-bottom:1px solid white;\n",
    "                font-size:18px;\n",
    "                font-weight:700;\n",
    "                font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
    "            }\n",
    "            QPushButton#left_button:hover{border-left:4px solid red;font-weight:700;}\n",
    "            QWidget#left_widget{\n",
    "                    background:gray;\n",
    "                    border-top:1px solid white;\n",
    "                    border-bottom:1px solid white;\n",
    "                    border-left:1px solid white;\n",
    "                    border-top-left-radius:10px;\n",
    "                    border-bottom-left-radius:10px;\n",
    "                }\n",
    "        ''')\n",
    " \n",
    "        \n",
    "        self.right_bar_widget_search_input.setStyleSheet(\n",
    "            '''QLineEdit{\n",
    "                    border:1px solid gray;\n",
    "                    width:300px;\n",
    "                    border-radius:10px;\n",
    "                    padding:2px 4px;\n",
    "            }''')\n",
    "        self.right_widget.setStyleSheet('''\n",
    "            QWidget#right_widget{\n",
    "                color:#232C51;\n",
    "                background:white;\n",
    "                border-top:1px solid darkGray;\n",
    "                border-bottom:1px solid darkGray;\n",
    "                border-right:1px solid darkGray;\n",
    "                border-top-right-radius:10px;\n",
    "                border-bottom-right-radius:10px;\n",
    "            }\n",
    "            QLabel#right_label{\n",
    "                border:none;\n",
    "                font-size:16px;\n",
    "                font-weight:700;\n",
    "                font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
    "            }\n",
    "        ''')\n",
    " \n",
    "        \n",
    "    def slot_btn_chooseFile(self):\n",
    "        fileName_choose, filetype = QFileDialog.getOpenFileName(self,  \n",
    "                                    \"选取文件\",  \n",
    "                                    self.cwd, # 起始路径 \n",
    "                                    \"All Files (*);;JPEG Files (*.jpg);;PNG Files (*.png);;TIF Files (*.tif)\")   # 设置文件扩展名过滤,用双分号间隔\n",
    "\n",
    "        if fileName_choose == \"\":\n",
    "            return\n",
    "\n",
    "        self.right_bar_widget_search_input.setText(fileName_choose)\n",
    "        jpg = QtGui.QPixmap(fileName_choose)\n",
    "        w=jpg.width()\n",
    "        h=jpg.height()\n",
    "        if w>=700:\n",
    "            jpg=jpg.scaled(700,round(h*700/w))\n",
    "        self.right_picture.setPixmap(jpg)\n",
    "        self.img_path=fileName_choose\n",
    "\n",
    "    def do_ocr(self):\n",
    "        img = cv2.imread(self.img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        if self.model==0:\n",
    "            re=''\n",
    "            rimg=cut_word(img)\n",
    "            for tmp in rimg:\n",
    "                re=re+''.join(evaluate(tmp)[0][:-1])+\" \"     \n",
    "                self.right_result.setText(re)\n",
    "        else:\n",
    "            result=''.join(evaluate(img)[0][:-1])\n",
    "            self.right_result.setText(result)\n",
    "                                      \n",
    "    def line_ocr(self):\n",
    "        self.model=0\n",
    "    def word_ocr(self):\n",
    "        self.model=1\n",
    " \n",
    "def main():\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    gui = MainUi()\n",
    "    gui.show()\n",
    "    sys.exit(app.exec_())\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    all_label_lang=np.load(\"./training_checkpoints/lang.npy\",allow_pickle=True).item()\n",
    "\n",
    "    encoder = Encoder(units)\n",
    "    decoder = Decoder(vocab_tar_size, embedding_dim, units*2)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,decay=0.02)\n",
    "\n",
    "    checkpoint_path = './training_checkpoints/81_train'\n",
    "    # checkpoint_path = './training_checkpoints/train10000'\n",
    "    ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                               decoder=decoder,\n",
    "                               optimizer = optimizer)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)\n",
    "\n",
    "    start_epoch = 0\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "        # restoring the latest checkpoint in checkpoint_path\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrieNode(object):\n",
    "#     def __init__(self, value=None, count=0, parent=None):\n",
    "#         # 值\n",
    "#         self.value = value\n",
    "#         # 频数统计\n",
    "#         self.count = count\n",
    "#         # 父结点\n",
    "#         self.parent = parent\n",
    "#         # 子节点，{value:TrieNode}\n",
    "#         self.children = {}\n",
    "\n",
    "\n",
    "# class Trie(object):\n",
    "#     def __init__(self):\n",
    "#         # 创建空的根节点\n",
    "#         self.root = TrieNode()\n",
    "#         self.lexicon=[]\n",
    "\n",
    "#     def insert(self, sequence):\n",
    "#         \"\"\"\n",
    "#         基操，插入一个序列\n",
    "#         :param sequence: 字符串\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         cur_node = self.root\n",
    "#         self.lexicon.append(sequence)\n",
    "#         for item in sequence:\n",
    "#             if item not in cur_node.children:\n",
    "#                 # 插入结点\n",
    "#                 child = TrieNode(value=item, count=1, parent=cur_node)\n",
    "#                 cur_node.children[item] = child\n",
    "#                 cur_node = child\n",
    "#             else:\n",
    "#                 # 更新结点\n",
    "#                 cur_node = cur_node.children[item]\n",
    "#                 cur_node.count += 1\n",
    "\n",
    "#     def search(self, sequence):\n",
    "#         \"\"\"\n",
    "#         基操，查询是否存在完整序列\n",
    "#         :param sequence: 字符串\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         cur_node = self.root\n",
    "# #         result=[]\n",
    "#         mark = True\n",
    "#         i=0\n",
    "#         for i in range(len(sequence)):\n",
    "#             item = sequence[i]\n",
    "#             print(self.lexicon)\n",
    "#             if item not in cur_node.children:\n",
    "#                 mark = False\n",
    "#                 print(item)\n",
    "#                 return self.min_distance(sequence,i)\n",
    "#             else:\n",
    "# #                 result.append(cur_node.value)\n",
    "#                 cur_node = cur_node.children[item]\n",
    "#         # 如果还有子结点，说明序列并非完整\n",
    "#         if cur_node.children:\n",
    "#             mark = False\n",
    "#         return self.min_distance(sequence,i)\n",
    "    \n",
    "#     def min_distance(self,sequence,i):\n",
    "#         mdis=5\n",
    "#         mw=sequence\n",
    "#         print(i)\n",
    "#         for w in self.lexicon:\n",
    "#             if i==0 or w.startswith(sequence[:i]):\n",
    "#                 print(w)\n",
    "#                 tmp = minDistance(sequence,w)\n",
    "#                 if mdis > tmp:\n",
    "#                     mdis = tmp\n",
    "#                     mw = w\n",
    "#         return mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyinstall -F "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
